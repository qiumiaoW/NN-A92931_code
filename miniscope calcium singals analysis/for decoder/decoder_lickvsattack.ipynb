{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = scipy.io.loadmat('E:/data/Ca_analyzing/Calb1_all_ca/final/decoder/lick_veus_attack.mat')\n",
    "lick_veus_attack = mat_data['lick_veus_attack']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "mat_data = scipy.io.loadmat('E:/data/Ca_analyzing/Calb1_all_ca/final/decoder/y_decoder_lickattack.mat')\n",
    "y_decoder_lickattack= mat_data['y_decoder_lickattack']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "# mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/twoeventshuffle.mat')\n",
    "# twoeventshuffle= mat_data['twoeventshuffle']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "mat_data = scipy.io.loadmat('E:/data/Ca_analyzing/Calb1_all_ca/final/decoder/twoeventshuffle3.mat')\n",
    "twoeventshuffle= mat_data['twoeventshuffle']  # 形状 (n_trials,n_neurons, t_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_decoder_lickattack[0]!=0\n",
    "Y=y_decoder_lickattack[0][mask]\n",
    "\n",
    "X = lick_veus_attack.reshape(2,203,222,1).transpose(1,0,2,3)#*0+np.random.rand(338,2,222,1)# neuron, trials,timepoints\n",
    "X=X [mask]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, stratify=Y, random_state=0)\n",
    "\n",
    "X = twoeventshuffle.reshape(2,203,222,1).transpose(1,0,2,3)#*0+np.random.rand(338,2,222,1)# neuron, trials,timepoints\n",
    "X=X [mask]\n",
    "Xs_train, Xs_test, Ys_train, Ys_test = train_test_split(X, Y, test_size=0.25, stratify=Y, random_state=0)\n",
    "\n",
    "# X = twoeventshuffle1.reshape(2,338,222,1).transpose(1,0,2,3)#*0+np.random.rand(338,2,222,1)# neuron, trials,timepoints\n",
    "# X=X [mask]\n",
    "# Xs1_train, Xs1_test, Ys1_train, Ys1_test = train_test_split(X, Y, test_size=0.25, stratify=Y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FD4746DE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FD51D213A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "o = {'Shuffle 1':[Xs_train, Xs_test, Y_train, Y_test],'True':[X_train, X_test, Y_train, Y_test]}\n",
    "F1_score = {}\n",
    "for isss in o:\n",
    "    F1_score[isss] = []\n",
    "    for m in range(100):\n",
    "        X_train, X_test, Y_train, Y_test = o[isss]\n",
    "\n",
    "    \n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(8, (1, 21), strides=(1,5), activation='relu', padding='SAME'),  # 使用 Conv2D\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(16, (1, 21), strides=(1,5), activation='relu', padding='SAME'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(32, (1, 21 ), strides=(1,5), activation='relu', padding='SAME'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(3, activation='softmax')  # 三分类问题\n",
    "        ])\n",
    "        # 编译模型\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(X_train, Y_train, epochs=100, batch_size=34, \n",
    "                            validation_data=(X_test, Y_test), \n",
    "                            verbose=0)\n",
    "        # 获取预测结果\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # 对于多分类问题，y_pred 需要转换为类标签\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)  # 获取预测的类标签\n",
    "\n",
    "        # 计算 F1-score（宏观平均 F1-score）\n",
    "        f1=f1_score(Y_test, y_pred_classes, average='weighted')  # 可以选择 'macro' 或 'weighted'\n",
    "        # F1_score[isss].append(np.sum((Y_test==np.argmax(model.predict(X_test),axis=-1))*(Y_test>0))/np.sum(Y_test>0))\n",
    "        F1_score[isss].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bodies': [<matplotlib.collections.PolyCollection at 0x1fd66fa85e0>,\n",
       "  <matplotlib.collections.PolyCollection at 0x1fd66fa8370>],\n",
       " 'cmaxes': <matplotlib.collections.LineCollection at 0x1fd66fa8d60>,\n",
       " 'cmins': <matplotlib.collections.LineCollection at 0x1fd58bc0b50>,\n",
       " 'cbars': <matplotlib.collections.LineCollection at 0x1fd58bc0340>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.violinplot(list(F1_score.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "F1_score_shuffle= pd.DataFrame(F1_score['Shuffle 1'], columns=['shuffle'])\n",
    "F1_score_shuffle.to_csv('E:/data/Ca_analyzing/Calb1_all_ca/final/decoder/lick_veus_attack_shuffle.csv', index=False)\n",
    "F1_score_true= pd.DataFrame(F1_score['True'], columns=['True'])\n",
    "F1_score_true.to_csv('E:/data/Ca_analyzing/Calb1_all_ca/final/decoder/lick_veus_attack_True.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/y_decoder_lick.mat')\n",
    "Y_decoder_lick = mat_data['y_decoder_lick']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/lick_av_dff.mat')\n",
    "lick_av_dff= mat_data['lick_av_dff']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/lick_shuffle_av_dff.mat')\n",
    "lick_shuffle_av_dff= mat_data['lick_shuffle_av_dff']  # 形状 (n_trials,n_neurons, t_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 1/100...\n",
      "Iteration 1 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 2/100...\n",
      "Iteration 2 - F1-score: 0.8571, Precision: 0.7500, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 3/100...\n",
      "Iteration 3 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 4/100...\n",
      "Iteration 4 - F1-score: 0.8000, Precision: 1.0000, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 5/100...\n",
      "Iteration 5 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 6/100...\n",
      "Iteration 6 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.8824\n",
      "Training iteration 7/100...\n",
      "Iteration 7 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 8/100...\n",
      "Iteration 8 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 9/100...\n",
      "Iteration 9 - F1-score: 0.8571, Precision: 0.7500, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 10/100...\n",
      "Iteration 10 - F1-score: 0.8000, Precision: 1.0000, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 11/100...\n",
      "Iteration 11 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.6765\n",
      "Training iteration 12/100...\n",
      "Iteration 12 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 13/100...\n",
      "Iteration 13 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 14/100...\n",
      "Iteration 14 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.7941\n",
      "Training iteration 15/100...\n",
      "Iteration 15 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 16/100...\n",
      "Iteration 16 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 17/100...\n",
      "Iteration 17 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 18/100...\n",
      "Iteration 18 - F1-score: 0.3333, Precision: 0.3333, Recall: 0.3333, Val Acc: 0.8824\n",
      "Training iteration 19/100...\n",
      "Iteration 19 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 20/100...\n",
      "Iteration 20 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 21/100...\n",
      "Iteration 21 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 22/100...\n",
      "Iteration 22 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 23/100...\n",
      "Iteration 23 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 24/100...\n",
      "Iteration 24 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 25/100...\n",
      "Iteration 25 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 26/100...\n",
      "Iteration 26 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 27/100...\n",
      "Iteration 27 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 28/100...\n",
      "Iteration 28 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 29/100...\n",
      "Iteration 29 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 30/100...\n",
      "Iteration 30 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 31/100...\n",
      "Iteration 31 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 32/100...\n",
      "Iteration 32 - F1-score: 0.5455, Precision: 0.3750, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 33/100...\n",
      "Iteration 33 - F1-score: 0.5455, Precision: 0.3750, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 34/100...\n",
      "Iteration 34 - F1-score: 0.5000, Precision: 1.0000, Recall: 0.3333, Val Acc: 0.9118\n",
      "Training iteration 35/100...\n",
      "Iteration 35 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.7059\n",
      "Training iteration 36/100...\n",
      "Iteration 36 - F1-score: 0.5000, Precision: 1.0000, Recall: 0.3333, Val Acc: 0.9412\n",
      "Training iteration 37/100...\n",
      "Iteration 37 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.9412\n",
      "Training iteration 38/100...\n",
      "Iteration 38 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 39/100...\n",
      "Iteration 39 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 40/100...\n",
      "Iteration 40 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 41/100...\n",
      "Iteration 41 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 42/100...\n",
      "Iteration 42 - F1-score: 0.8571, Precision: 0.7500, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 43/100...\n",
      "Iteration 43 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 44/100...\n",
      "Iteration 44 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 45/100...\n",
      "Iteration 45 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 46/100...\n",
      "Iteration 46 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 47/100...\n",
      "Iteration 47 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 48/100...\n",
      "Iteration 48 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 49/100...\n",
      "Iteration 49 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 50/100...\n",
      "Iteration 50 - F1-score: 0.3333, Precision: 0.2222, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 51/100...\n",
      "Iteration 51 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 52/100...\n",
      "Iteration 52 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 53/100...\n",
      "Iteration 53 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 54/100...\n",
      "Iteration 54 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 55/100...\n",
      "Iteration 55 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 56/100...\n",
      "Iteration 56 - F1-score: 0.3333, Precision: 0.2222, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 57/100...\n",
      "Iteration 57 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 58/100...\n",
      "Iteration 58 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 59/100...\n",
      "Iteration 59 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 60/100...\n",
      "Iteration 60 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 1.0000\n",
      "Training iteration 61/100...\n",
      "Iteration 61 - F1-score: 0.8000, Precision: 1.0000, Recall: 0.6667, Val Acc: 0.9706\n",
      "Training iteration 62/100...\n",
      "Iteration 62 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 63/100...\n",
      "Iteration 63 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 64/100...\n",
      "Iteration 64 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.7647\n",
      "Training iteration 65/100...\n",
      "Iteration 65 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 66/100...\n",
      "Iteration 66 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 67/100...\n",
      "Iteration 67 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 68/100...\n",
      "Iteration 68 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 69/100...\n",
      "Iteration 69 - F1-score: 0.8571, Precision: 0.7500, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 70/100...\n",
      "Iteration 70 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.9706\n",
      "Training iteration 71/100...\n",
      "Iteration 71 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 72/100...\n",
      "Iteration 72 - F1-score: 0.3333, Precision: 0.3333, Recall: 0.3333, Val Acc: 0.9118\n",
      "Training iteration 73/100...\n",
      "Iteration 73 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 74/100...\n",
      "Iteration 74 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 75/100...\n",
      "Iteration 75 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 76/100...\n",
      "Iteration 76 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 77/100...\n",
      "Iteration 77 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 78/100...\n",
      "Iteration 78 - F1-score: 0.2222, Precision: 0.1667, Recall: 0.3333, Val Acc: 0.7941\n",
      "Training iteration 79/100...\n",
      "Iteration 79 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 80/100...\n",
      "Iteration 80 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.9118\n",
      "Training iteration 81/100...\n",
      "Iteration 81 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 82/100...\n",
      "Iteration 82 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 83/100...\n",
      "Iteration 83 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 84/100...\n",
      "Iteration 84 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 85/100...\n",
      "Iteration 85 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 86/100...\n",
      "Iteration 86 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 87/100...\n",
      "Iteration 87 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 88/100...\n",
      "Iteration 88 - F1-score: 0.3333, Precision: 0.3333, Recall: 0.3333, Val Acc: 0.8824\n",
      "Training iteration 89/100...\n",
      "Iteration 89 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 90/100...\n",
      "Iteration 90 - F1-score: 0.2222, Precision: 0.1667, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 91/100...\n",
      "Iteration 91 - F1-score: 0.4615, Precision: 0.3000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 92/100...\n",
      "Iteration 92 - F1-score: 0.6667, Precision: 0.6667, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 93/100...\n",
      "Iteration 93 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 94/100...\n",
      "Iteration 94 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.7941\n",
      "Training iteration 95/100...\n",
      "Iteration 95 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8235\n",
      "Training iteration 96/100...\n",
      "Iteration 96 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.7647\n",
      "Training iteration 97/100...\n",
      "Iteration 97 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 98/100...\n",
      "Iteration 98 - F1-score: 0.2857, Precision: 0.2500, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 99/100...\n",
      "Iteration 99 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 100/100...\n",
      "Iteration 100 - F1-score: 0.3333, Precision: 0.3333, Recall: 0.3333, Val Acc: 0.8529\n",
      "\n",
      "Average F1-score: 0.5670 ± 0.1963\n",
      "Average Validation Accuracy: 0.8715 ± 0.0599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 预处理数据\n",
    "X = lick_av_dff.reshape(338, 222, 1)  # (batch_size, time_steps, channels)\n",
    "Y = np.array(Y_decoder_lick[0])  # 二分类标签\n",
    "\n",
    "# 处理类别不均衡\n",
    "class_weights = {0: 0.55, 1: 5.17}  # 0 类占比高，1 类占比低\n",
    "\n",
    "repeat_times = 100\n",
    "F1_scores, decoding_accuracies = [], []\n",
    "\n",
    "for i in range(repeat_times):\n",
    "    print(f\"Training iteration {i+1}/{repeat_times}...\")\n",
    "\n",
    "    # 重新划分训练集和测试集\n",
    "    x_train, x_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.1, stratify=Y, random_state=i  # 保证每次划分一致\n",
    "    )\n",
    "\n",
    "    # 重新构建模型\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(8, 20, activation='relu', padding='SAME'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv1D(16, 20, activation='relu', padding='SAME'),\n",
    "        tf.keras.layers.Dropout(0.3), #防止过拟合\n",
    "        tf.keras.layers.Conv1D(32, 20, activation='relu', padding='SAME', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # 单分类选择类型\n",
    "\n",
    "    # 训练模型，加入 EarlyStopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        x_train, Y_train, epochs=100, batch_size=34,\n",
    "        validation_data=(x_test, Y_test), shuffle=True,\n",
    "        callbacks=[early_stop], class_weight=class_weights,\n",
    "        verbose=0  # 关闭详细日志，提高运行效率\n",
    "    )\n",
    "\n",
    "    # 计算 F1-score\n",
    "    y_pred = (model.predict(x_test, verbose=0) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    val_acc = history.history['val_accuracy'][-1] if 'val_accuracy' in history.history else 0  # 防止EarlyStopping过早停止\n",
    "\n",
    "    decoding_accuracies.append(val_acc)\n",
    "    F1_scores.append(f1)\n",
    "\n",
    "    print(f\"Iteration {i+1} - F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# 计算平均 F1-score 和 Accuracy\n",
    "print(f\"\\nAverage F1-score: {np.mean(F1_scores):.4f} ± {np.std(F1_scores):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(decoding_accuracies):.4f} ± {np.std(decoding_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 1/100...\n",
      "Iteration 1 - F1-score: 0.3077, Precision: 0.2000, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 2/100...\n",
      "Iteration 2 - F1-score: 0.2222, Precision: 0.1667, Recall: 0.3333, Val Acc: 0.6471\n",
      "Training iteration 3/100...\n",
      "Iteration 3 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 4/100...\n",
      "Iteration 4 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8824\n",
      "Training iteration 5/100...\n",
      "Iteration 5 - F1-score: 0.1667, Precision: 0.1111, Recall: 0.3333, Val Acc: 0.7353\n",
      "Training iteration 6/100...\n",
      "Iteration 6 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 7/100...\n",
      "Iteration 7 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.7353\n",
      "Training iteration 8/100...\n",
      "Iteration 8 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.7941\n",
      "Training iteration 9/100...\n",
      "Iteration 9 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 10/100...\n",
      "Iteration 10 - F1-score: 0.5455, Precision: 0.3750, Recall: 1.0000, Val Acc: 0.7941\n",
      "Training iteration 11/100...\n",
      "Iteration 11 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 12/100...\n",
      "Iteration 12 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 13/100...\n",
      "Iteration 13 - F1-score: 0.2857, Precision: 0.2500, Recall: 0.3333, Val Acc: 0.7353\n",
      "Training iteration 14/100...\n",
      "Iteration 14 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.7647\n",
      "Training iteration 15/100...\n",
      "Iteration 15 - F1-score: 0.3077, Precision: 0.2000, Recall: 0.6667, Val Acc: 0.7353\n",
      "Training iteration 16/100...\n",
      "Iteration 16 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 17/100...\n",
      "Iteration 17 - F1-score: 0.3333, Precision: 0.2222, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 18/100...\n",
      "Iteration 18 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 19/100...\n",
      "Iteration 19 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 20/100...\n",
      "Iteration 20 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 21/100...\n",
      "Iteration 21 - F1-score: 0.3636, Precision: 0.2500, Recall: 0.6667, Val Acc: 0.7059\n",
      "Training iteration 22/100...\n",
      "Iteration 22 - F1-score: 0.3333, Precision: 0.2222, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 23/100...\n",
      "Iteration 23 - F1-score: 0.4286, Precision: 0.2727, Recall: 1.0000, Val Acc: 0.6765\n",
      "Training iteration 24/100...\n",
      "Iteration 24 - F1-score: 0.3636, Precision: 0.2500, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 25/100...\n",
      "Iteration 25 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 26/100...\n",
      "Iteration 26 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.7353\n",
      "Training iteration 27/100...\n",
      "Iteration 27 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.8824\n",
      "Training iteration 28/100...\n",
      "Iteration 28 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 29/100...\n",
      "Iteration 29 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.7941\n",
      "Training iteration 30/100...\n",
      "Iteration 30 - F1-score: 0.4615, Precision: 0.3000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 31/100...\n",
      "Iteration 31 - F1-score: 0.1667, Precision: 0.1111, Recall: 0.3333, Val Acc: 0.6765\n",
      "Training iteration 32/100...\n",
      "Iteration 32 - F1-score: 0.4000, Precision: 0.2500, Recall: 1.0000, Val Acc: 0.7059\n",
      "Training iteration 33/100...\n",
      "Iteration 33 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8235\n",
      "Training iteration 34/100...\n",
      "Iteration 34 - F1-score: 0.3636, Precision: 0.2500, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 35/100...\n",
      "Iteration 35 - F1-score: 0.2857, Precision: 0.1818, Recall: 0.6667, Val Acc: 0.7353\n",
      "Training iteration 36/100...\n",
      "Iteration 36 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 37/100...\n",
      "Iteration 37 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.5588\n",
      "Training iteration 38/100...\n",
      "Iteration 38 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 39/100...\n",
      "Iteration 39 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 40/100...\n",
      "Iteration 40 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.9118\n",
      "Training iteration 41/100...\n",
      "Iteration 41 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 42/100...\n",
      "Iteration 42 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 43/100...\n",
      "Iteration 43 - F1-score: 0.1818, Precision: 0.1250, Recall: 0.3333, Val Acc: 0.7941\n",
      "Training iteration 44/100...\n",
      "Iteration 44 - F1-score: 0.2857, Precision: 0.2500, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 45/100...\n",
      "Iteration 45 - F1-score: 0.8000, Precision: 1.0000, Recall: 0.6667, Val Acc: 0.9412\n",
      "Training iteration 46/100...\n",
      "Iteration 46 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 47/100...\n",
      "Iteration 47 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.7353\n",
      "Training iteration 48/100...\n",
      "Iteration 48 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 49/100...\n",
      "Iteration 49 - F1-score: 0.2222, Precision: 0.1667, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 50/100...\n",
      "Iteration 50 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 51/100...\n",
      "Iteration 51 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 52/100...\n",
      "Iteration 52 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8529\n",
      "Training iteration 53/100...\n",
      "Iteration 53 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8824\n",
      "Training iteration 54/100...\n",
      "Iteration 54 - F1-score: 0.2222, Precision: 0.1667, Recall: 0.3333, Val Acc: 0.6765\n",
      "Training iteration 55/100...\n",
      "Iteration 55 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 56/100...\n",
      "Iteration 56 - F1-score: 0.2667, Precision: 0.1667, Recall: 0.6667, Val Acc: 0.6471\n",
      "Training iteration 57/100...\n",
      "Iteration 57 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.8235\n",
      "Training iteration 58/100...\n",
      "Iteration 58 - F1-score: 0.3529, Precision: 0.2143, Recall: 1.0000, Val Acc: 0.6765\n",
      "Training iteration 59/100...\n",
      "Iteration 59 - F1-score: 0.1818, Precision: 0.1250, Recall: 0.3333, Val Acc: 0.7353\n",
      "Training iteration 60/100...\n",
      "Iteration 60 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 61/100...\n",
      "Iteration 61 - F1-score: 0.1538, Precision: 0.1000, Recall: 0.3333, Val Acc: 0.6765\n",
      "Training iteration 62/100...\n",
      "Iteration 62 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8529\n",
      "Training iteration 63/100...\n",
      "Iteration 63 - F1-score: 0.5714, Precision: 0.5000, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 64/100...\n",
      "Iteration 64 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 65/100...\n",
      "Iteration 65 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8824\n",
      "Training iteration 66/100...\n",
      "Iteration 66 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 67/100...\n",
      "Iteration 67 - F1-score: 0.3333, Precision: 0.2222, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 68/100...\n",
      "Iteration 68 - F1-score: 0.3333, Precision: 0.2222, Recall: 0.6667, Val Acc: 0.7059\n",
      "Training iteration 69/100...\n",
      "Iteration 69 - F1-score: 0.2857, Precision: 0.2500, Recall: 0.3333, Val Acc: 0.7941\n",
      "Training iteration 70/100...\n",
      "Iteration 70 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 71/100...\n",
      "Iteration 71 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.7353\n",
      "Training iteration 72/100...\n",
      "Iteration 72 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8824\n",
      "Training iteration 73/100...\n",
      "Iteration 73 - F1-score: 0.4615, Precision: 0.3000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 74/100...\n",
      "Iteration 74 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7647\n",
      "Training iteration 75/100...\n",
      "Iteration 75 - F1-score: 0.2500, Precision: 0.1538, Recall: 0.6667, Val Acc: 0.6471\n",
      "Training iteration 76/100...\n",
      "Iteration 76 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.7941\n",
      "Training iteration 77/100...\n",
      "Iteration 77 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8235\n",
      "Training iteration 78/100...\n",
      "Iteration 78 - F1-score: 0.5455, Precision: 0.3750, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 79/100...\n",
      "Iteration 79 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 80/100...\n",
      "Iteration 80 - F1-score: 0.1538, Precision: 0.1000, Recall: 0.3333, Val Acc: 0.6471\n",
      "Training iteration 81/100...\n",
      "Iteration 81 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 82/100...\n",
      "Iteration 82 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8529\n",
      "Training iteration 83/100...\n",
      "Iteration 83 - F1-score: 0.7500, Precision: 0.6000, Recall: 1.0000, Val Acc: 0.7353\n",
      "Training iteration 84/100...\n",
      "Iteration 84 - F1-score: 0.2000, Precision: 0.1429, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 85/100...\n",
      "Iteration 85 - F1-score: 0.5000, Precision: 0.3333, Recall: 1.0000, Val Acc: 0.7059\n",
      "Training iteration 86/100...\n",
      "Iteration 86 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 87/100...\n",
      "Iteration 87 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 88/100...\n",
      "Iteration 88 - F1-score: 0.2667, Precision: 0.1667, Recall: 0.6667, Val Acc: 0.6765\n",
      "Training iteration 89/100...\n",
      "Iteration 89 - F1-score: 0.3077, Precision: 0.2000, Recall: 0.6667, Val Acc: 0.6765\n",
      "Training iteration 90/100...\n",
      "Iteration 90 - F1-score: 0.4000, Precision: 0.5000, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 91/100...\n",
      "Iteration 91 - F1-score: 0.5000, Precision: 0.4000, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 92/100...\n",
      "Iteration 92 - F1-score: 0.2857, Precision: 0.2500, Recall: 0.3333, Val Acc: 0.8529\n",
      "Training iteration 93/100...\n",
      "Iteration 93 - F1-score: 0.4000, Precision: 0.2857, Recall: 0.6667, Val Acc: 0.8235\n",
      "Training iteration 94/100...\n",
      "Iteration 94 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 95/100...\n",
      "Iteration 95 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.7647\n",
      "Training iteration 96/100...\n",
      "Iteration 96 - F1-score: 0.6000, Precision: 0.4286, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 97/100...\n",
      "Iteration 97 - F1-score: 0.2500, Precision: 0.2000, Recall: 0.3333, Val Acc: 0.7647\n",
      "Training iteration 98/100...\n",
      "Iteration 98 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.8529\n",
      "Training iteration 99/100...\n",
      "Iteration 99 - F1-score: 0.4444, Precision: 0.3333, Recall: 0.6667, Val Acc: 0.7941\n",
      "Training iteration 100/100...\n",
      "Iteration 100 - F1-score: 0.1667, Precision: 0.1111, Recall: 0.3333, Val Acc: 0.7647\n",
      "\n",
      "Average F1-score: 0.3316 ± 0.1877\n",
      "Average Validation Accuracy: 0.7888 ± 0.0698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 预处理数据\n",
    "X = lick_shuffle_av_dff.reshape(338, 222, 1)  # (batch_size, time_steps, channels)\n",
    "Y = np.array(Y_decoder_lick[0])  # 二分类标签\n",
    "\n",
    "# 处理类别不均衡\n",
    "class_weights = {0: 0.55, 1: 5.17}  # 0 类占比高，1 类占比低\n",
    "\n",
    "repeat_times = 100\n",
    "F1_scores, decoding_accuracies = [], []\n",
    "\n",
    "for i in range(repeat_times):\n",
    "    print(f\"Training iteration {i+1}/{repeat_times}...\")\n",
    "\n",
    "    # 重新划分训练集和测试集\n",
    "    x_train, x_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.1, stratify=Y, random_state=i  # 保证每次划分一致\n",
    "    )\n",
    "\n",
    "    # 重新构建模型\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(8, 20, activation='relu', padding='SAME'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv1D(16, 20, activation='relu', padding='SAME'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv1D(32, 20, activation='relu', padding='SAME', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 训练模型，加入 EarlyStopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        x_train, Y_train, epochs=100, batch_size=34,\n",
    "        validation_data=(x_test, Y_test), shuffle=True,\n",
    "        callbacks=[early_stop], class_weight=class_weights,\n",
    "        verbose=0  # 关闭详细日志，提高运行效率\n",
    "    )\n",
    "\n",
    "    # 计算 F1-score\n",
    "    y_pred = (model.predict(x_test, verbose=0) > 0.5).astype(int)\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    val_acc = history.history['val_accuracy'][-1] if 'val_accuracy' in history.history else 0  # 防止EarlyStopping过早停止\n",
    "\n",
    "    decoding_accuracies.append(val_acc)\n",
    "    F1_scores.append(f1)\n",
    "\n",
    "    print(f\"Iteration {i+1} - F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# 计算平均 F1-score 和 Accuracy\n",
    "print(f\"\\nAverage F1-score: {np.mean(F1_scores):.4f} ± {np.std(F1_scores):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(decoding_accuracies):.4f} ± {np.std(decoding_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/y_decoder_attack.mat')\n",
    "y_decoder_attack = mat_data['y_decoder_attack']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/attack_av_dff.mat')\n",
    "attack_av_dff= mat_data['attack_av_dff']  # 形状 (n_trials,n_neurons, t_timepoints)\n",
    "mat_data = scipy.io.loadmat('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/attack_shuffle_av_dff.mat')\n",
    "attack_shuffle_av_dff= mat_data['attack_shuffle_av_dff']  # 形状 (n_trials,n_neurons, t_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 1/100...\n",
      "Iteration 1 - F1-score: 0.0000, Precision: 0.0000, Recall: 0.0000, Val Acc: 0.8824\n",
      "Training iteration 2/100...\n",
      "Iteration 2 - F1-score: 0.5000, Precision: 0.5000, Recall: 0.5000, Val Acc: 0.8824\n",
      "Training iteration 3/100...\n",
      "Iteration 3 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 4/100...\n",
      "Iteration 4 - F1-score: 0.5455, Precision: 0.4286, Recall: 0.7500, Val Acc: 0.8235\n",
      "Training iteration 5/100...\n",
      "Iteration 5 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.9412\n",
      "Training iteration 6/100...\n",
      "Iteration 6 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 7/100...\n",
      "Iteration 7 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 8/100...\n",
      "Iteration 8 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 9/100...\n",
      "Iteration 9 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 10/100...\n",
      "Iteration 10 - F1-score: 0.5000, Precision: 0.5000, Recall: 0.5000, Val Acc: 0.8824\n",
      "Training iteration 11/100...\n",
      "Iteration 11 - F1-score: 0.4000, Precision: 0.3333, Recall: 0.5000, Val Acc: 0.8235\n",
      "Training iteration 12/100...\n",
      "Iteration 12 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 13/100...\n",
      "Iteration 13 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.9706\n",
      "Training iteration 14/100...\n",
      "Iteration 14 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9412\n",
      "Training iteration 15/100...\n",
      "Iteration 15 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 16/100...\n",
      "Iteration 16 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 17/100...\n",
      "Iteration 17 - F1-score: 0.4444, Precision: 0.4000, Recall: 0.5000, Val Acc: 0.8235\n",
      "Training iteration 18/100...\n",
      "Iteration 18 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9412\n",
      "Training iteration 19/100...\n",
      "Iteration 19 - F1-score: 0.4615, Precision: 0.3333, Recall: 0.7500, Val Acc: 0.7647\n",
      "Training iteration 20/100...\n",
      "Iteration 20 - F1-score: 0.4286, Precision: 0.3000, Recall: 0.7500, Val Acc: 0.6765\n",
      "Training iteration 21/100...\n",
      "Iteration 21 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 22/100...\n",
      "Iteration 22 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 23/100...\n",
      "Iteration 23 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 24/100...\n",
      "Iteration 24 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 25/100...\n",
      "Iteration 25 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 26/100...\n",
      "Iteration 26 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.9706\n",
      "Training iteration 27/100...\n",
      "Iteration 27 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 28/100...\n",
      "Iteration 28 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 29/100...\n",
      "Iteration 29 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 30/100...\n",
      "Iteration 30 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 31/100...\n",
      "Iteration 31 - F1-score: 0.2857, Precision: 0.3333, Recall: 0.2500, Val Acc: 0.8235\n",
      "Training iteration 32/100...\n",
      "Iteration 32 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 33/100...\n",
      "Iteration 33 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.9706\n",
      "Training iteration 34/100...\n",
      "Iteration 34 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 35/100...\n",
      "Iteration 35 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 1.0000\n",
      "Training iteration 36/100...\n",
      "Iteration 36 - F1-score: 0.5714, Precision: 0.4000, Recall: 1.0000, Val Acc: 0.7647\n",
      "Training iteration 37/100...\n",
      "Iteration 37 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 38/100...\n",
      "Iteration 38 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9412\n",
      "Training iteration 39/100...\n",
      "Iteration 39 - F1-score: 0.4615, Precision: 0.3333, Recall: 0.7500, Val Acc: 0.7059\n",
      "Training iteration 40/100...\n",
      "Iteration 40 - F1-score: 0.6154, Precision: 0.4444, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 41/100...\n",
      "Iteration 41 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 42/100...\n",
      "Iteration 42 - F1-score: 0.3636, Precision: 0.2857, Recall: 0.5000, Val Acc: 0.8529\n",
      "Training iteration 43/100...\n",
      "Iteration 43 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 44/100...\n",
      "Iteration 44 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 45/100...\n",
      "Iteration 45 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 46/100...\n",
      "Iteration 46 - F1-score: 0.5000, Precision: 0.5000, Recall: 0.5000, Val Acc: 0.8529\n",
      "Training iteration 47/100...\n",
      "Iteration 47 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 48/100...\n",
      "Iteration 48 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 49/100...\n",
      "Iteration 49 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 50/100...\n",
      "Iteration 50 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 51/100...\n",
      "Iteration 51 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 52/100...\n",
      "Iteration 52 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.7353\n",
      "Training iteration 53/100...\n",
      "Iteration 53 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 54/100...\n",
      "Iteration 54 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 55/100...\n",
      "Iteration 55 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 56/100...\n",
      "Iteration 56 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 57/100...\n",
      "Iteration 57 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.9706\n",
      "Training iteration 58/100...\n",
      "Iteration 58 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9412\n",
      "Training iteration 59/100...\n",
      "Iteration 59 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.8529\n",
      "Training iteration 60/100...\n",
      "Iteration 60 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 61/100...\n",
      "Iteration 61 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 62/100...\n",
      "Iteration 62 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 63/100...\n",
      "Iteration 63 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 64/100...\n",
      "Iteration 64 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 65/100...\n",
      "Iteration 65 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 66/100...\n",
      "Iteration 66 - F1-score: 0.5714, Precision: 0.4000, Recall: 1.0000, Val Acc: 0.7941\n",
      "Training iteration 67/100...\n",
      "Iteration 67 - F1-score: 0.6154, Precision: 0.4444, Recall: 1.0000, Val Acc: 0.7941\n",
      "Training iteration 68/100...\n",
      "Iteration 68 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 69/100...\n",
      "Iteration 69 - F1-score: 0.5714, Precision: 0.4000, Recall: 1.0000, Val Acc: 0.7941\n",
      "Training iteration 70/100...\n",
      "Iteration 70 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 71/100...\n",
      "Iteration 71 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8824\n",
      "Training iteration 72/100...\n",
      "Iteration 72 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.8235\n",
      "Training iteration 73/100...\n",
      "Iteration 73 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 74/100...\n",
      "Iteration 74 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 75/100...\n",
      "Iteration 75 - F1-score: 0.4444, Precision: 0.4000, Recall: 0.5000, Val Acc: 0.8529\n",
      "Training iteration 76/100...\n",
      "Iteration 76 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 77/100...\n",
      "Iteration 77 - F1-score: 0.6154, Precision: 0.4444, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 78/100...\n",
      "Iteration 78 - F1-score: 0.5000, Precision: 0.5000, Recall: 0.5000, Val Acc: 0.8529\n",
      "Training iteration 79/100...\n",
      "Iteration 79 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 80/100...\n",
      "Iteration 80 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 81/100...\n",
      "Iteration 81 - F1-score: 0.5714, Precision: 0.6667, Recall: 0.5000, Val Acc: 0.9412\n",
      "Training iteration 82/100...\n",
      "Iteration 82 - F1-score: 0.5455, Precision: 0.4286, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 83/100...\n",
      "Iteration 83 - F1-score: 0.7500, Precision: 0.7500, Recall: 0.7500, Val Acc: 0.9412\n",
      "Training iteration 84/100...\n",
      "Iteration 84 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 85/100...\n",
      "Iteration 85 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 86/100...\n",
      "Iteration 86 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.8824\n",
      "Training iteration 87/100...\n",
      "Iteration 87 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 1.0000\n",
      "Training iteration 88/100...\n",
      "Iteration 88 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 89/100...\n",
      "Iteration 89 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9706\n",
      "Training iteration 90/100...\n",
      "Iteration 90 - F1-score: 0.6000, Precision: 0.5000, Recall: 0.7500, Val Acc: 0.8529\n",
      "Training iteration 91/100...\n",
      "Iteration 91 - F1-score: 0.6667, Precision: 0.6000, Recall: 0.7500, Val Acc: 0.9118\n",
      "Training iteration 92/100...\n",
      "Iteration 92 - F1-score: 0.8889, Precision: 0.8000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 93/100...\n",
      "Iteration 93 - F1-score: 0.7273, Precision: 0.5714, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 94/100...\n",
      "Iteration 94 - F1-score: 1.0000, Precision: 1.0000, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 95/100...\n",
      "Iteration 95 - F1-score: 0.3636, Precision: 0.2857, Recall: 0.5000, Val Acc: 0.6765\n",
      "Training iteration 96/100...\n",
      "Iteration 96 - F1-score: 0.5000, Precision: 0.5000, Recall: 0.5000, Val Acc: 0.9118\n",
      "Training iteration 97/100...\n",
      "Iteration 97 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 98/100...\n",
      "Iteration 98 - F1-score: 0.6667, Precision: 0.5000, Recall: 1.0000, Val Acc: 0.9118\n",
      "Training iteration 99/100...\n",
      "Iteration 99 - F1-score: 0.8000, Precision: 0.6667, Recall: 1.0000, Val Acc: 0.9412\n",
      "Training iteration 100/100...\n",
      "Iteration 100 - F1-score: 0.8571, Precision: 1.0000, Recall: 0.7500, Val Acc: 0.9412\n",
      "\n",
      "Average F1-score: 0.6956 ± 0.1749\n",
      "Average Validation Accuracy: 0.8859 ± 0.0630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 预处理数据\n",
    "X = attack_av_dff.reshape(338, 222, 1)  # (batch_size, time_steps, channels)\n",
    "Y = np.array(y_decoder_attack[0])  # 二分类标签\n",
    "\n",
    "# 处理类别不均衡\n",
    "class_weights = {0: 0.55, 1: 5.17}  # 0 类占比高，1 类占比低\n",
    "\n",
    "repeat_times = 100\n",
    "F1_scores, decoding_accuracies = [], []\n",
    "\n",
    "for i in range(repeat_times):\n",
    "    print(f\"Training iteration {i+1}/{repeat_times}...\")\n",
    "\n",
    "    # 重新划分训练集和测试集\n",
    "    x_train, x_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.1, stratify=Y, random_state=i  # 保证每次划分一致\n",
    "    )\n",
    "\n",
    "    # 重新构建模型\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(8, 20, activation='relu', padding='SAME'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv1D(16, 20, activation='relu', padding='SAME'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv1D(32, 20, activation='relu', padding='SAME', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 训练模型，加入 EarlyStopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        x_train, Y_train, epochs=100, batch_size=34,\n",
    "        validation_data=(x_test, Y_test), shuffle=True,\n",
    "        callbacks=[early_stop], class_weight=class_weights,\n",
    "        verbose=0  # 关闭详细日志，提高运行效率\n",
    "    )\n",
    "\n",
    "    # 计算 F1-score\n",
    "    y_pred = (model.predict(x_test, verbose=0) > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    val_acc = history.history['val_accuracy'][-1] if 'val_accuracy' in history.history else 0  # 防止EarlyStopping过早停止\n",
    "\n",
    "    decoding_accuracies.append(val_acc)\n",
    "    F1_scores.append(f1)\n",
    "\n",
    "    print(f\"Iteration {i+1} - F1-score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# 计算平均 F1-score 和 Accuracy\n",
    "print(f\"\\nAverage F1-score: {np.mean(F1_scores):.4f} ± {np.std(F1_scores):.4f}\")\n",
    "print(f\"Average Validation Accuracy: {np.mean(decoding_accuracies):.4f} ± {np.std(decoding_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# F1_score= pd.DataFrame(F1_scores, columns=['lickdecoding'])\n",
    "# F1_score.to_csv('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder\\lickdecoding_F1.csv', index=False)\n",
    "# F1_score= pd.DataFrame(F1_scores, columns=['lickshuffledecoding'])\n",
    "# F1_score.to_csv('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder\\lickdeshuffle_F1.csv', index=False)\n",
    "# F1_score= pd.DataFrame(F1_scores, columns=['attackdecoding'])\n",
    "# F1_score.to_csv('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/attackcoding_F1.csv', index=False)\n",
    "F1_score= pd.DataFrame(F1_scores, columns=['attackshuffledecoding'])\n",
    "F1_score.to_csv('E:\\data\\Ca_analyzing\\Calb1_all_ca/for PCA\\decoder/attackshuffle_F1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "A = [(j,i) for i,j in zip(X,Y)]\n",
    "A.sort(key=lambda x: x[0])\n",
    "fig = plt.figure(figsize=(1,20))\n",
    "B = []\n",
    "c = 0\n",
    "for i in A:\n",
    "    if i[0]==1:\n",
    "        m = np.random.rand()<1\n",
    "    else:\n",
    "        m = np.random.rand()<0.1\n",
    "    if m:\n",
    "        _norm = i[1]/np.max(i[1])*0.5+0.5\n",
    "        plt.plot(_norm+c*2,color='#555555')\n",
    "        plt.axhline(c*2)\n",
    "        B.append(i[0])\n",
    "        c += 1\n",
    "plt.yticks([i*2+1 for i in range(len(B))],B)\n",
    "plt.ylim(0,c*2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuronVis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
